{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30f6f324",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d15951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report,accuracy_score,\\\n",
    "log_loss,confusion_matrix\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f1f801",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d7d6abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"bank.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e49958d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['ID'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7776cb72",
   "metadata": {},
   "source": [
    "### Downsampling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c874548",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_class=df[df['Personal Loan']==1]\n",
    "zero_class=df[df['Personal Loan']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c27d95f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_downsample = resample(zero_class,\n",
    "             replace=True,\n",
    "             n_samples=len(one_class),\n",
    "             random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "332384bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([zero_downsample,one_class])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716710a4",
   "metadata": {},
   "source": [
    "### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3917281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(['Personal Loan'],axis=1).values\n",
    "Y=data['Personal Loan'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88ec055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f27392f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15e3a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16fcd8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bc5248",
   "metadata": {},
   "source": [
    "### Cultural Algorithm for Weight Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f73b85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CulturalNN:\n",
    "    def __init__(self, X_train, y_train,hidden_layer=10, chromosomes=30,\n",
    "                 belief_space_agents=10, generations=30, mating_parents=10, crossover_rate=0.8,\n",
    "                 mutation_rate=0.1):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.chromosomes = chromosomes\n",
    "        self.belief_space_agents = belief_space_agents\n",
    "        self.generations = generations\n",
    "        self.mating_parents = mating_parents\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.input_layer = X_train.shape[1]\n",
    "        self.output_layer = 1\n",
    "        self.genes = self.input_layer*self.hidden_layer + self.hidden_layer + \\\n",
    "            self.hidden_layer*self.output_layer + self.output_layer\n",
    "        self.pop_size = (self.chromosomes, self.genes)\n",
    "        self.population = np.random.rand(*self.pop_size)\n",
    "        self.population = 2*self.population - 1\n",
    "        self.belief_space = np.random.rand(self.belief_space_agents, self.genes)\n",
    "        self.belief_space = 2*self.belief_space - 1\n",
    "        self.best_weights=None\n",
    "\n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "\n",
    "    def relu(self,x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def forward(self, inputs, weights):\n",
    "        weight1 = np.reshape(weights[:self.hidden_layer*self.input_layer], (self.hidden_layer, self.input_layer))\n",
    "        bias1 = np.reshape(weights[self.hidden_layer*self.input_layer:self.hidden_layer*self.input_layer+self.hidden_layer], (self.output_layer,self.hidden_layer))\n",
    "        weight2 = np.reshape(weights[self.hidden_layer*self.input_layer+self.hidden_layer:-1], (self.output_layer, self.hidden_layer))\n",
    "        bias2 = np.reshape(weights[-1], (self.output_layer, 1))\n",
    "\n",
    "        A0 = inputs\n",
    "        Z1 = A0.dot(weight1.T)+bias1\n",
    "        A1 = self.relu(Z1)\n",
    "        Z2 = A1.dot(weight2.T)+bias2\n",
    "        A2 = self.sigmoid(Z2)\n",
    "        y_pred = np.round(A2)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def fitness_function(self, inputs, population, y_train):\n",
    "        fitness = []\n",
    "        for weights in population:\n",
    "            y_pred = self.forward(inputs, weights)\n",
    "            acc = accuracy_score(y_train, y_pred)\n",
    "            fitness.append(acc)\n",
    "\n",
    "        return fitness\n",
    "\n",
    "    def acceptance_function(self, belief_space, new_agent, fitness, new_agent_fitness):\n",
    "        min_fitness_index = np.argmin(fitness)\n",
    "\n",
    "        if fitness[min_fitness_index] < new_agent_fitness:\n",
    "            belief_space[min_fitness_index, :] = new_agent\n",
    "\n",
    "        return belief_space\n",
    "\n",
    "    def influence_function(self, mating_parents, fitness_belief, fitness_population):\n",
    "        num_belief_parents = mating_parents//2\n",
    "        parents_belief_space = self.belief_space[np.random.choice(self.belief_space.shape[0], num_belief_parents, replace=False)]\n",
    "        sorted_pop = self.population[fitness_population.argsort()]\n",
    "        num_pop_parents = mating_parents - num_belief_parents\n",
    "        parents_population = sorted_pop[:num_pop_parents, :]\n",
    "        parents = np.concatenate((parents_belief_space, parents_population))\n",
    "\n",
    "        return parents\n",
    "    \n",
    "    \n",
    "    def crossover(self, parents, offspring_size):\n",
    "        offspring = np.empty(offspring_size)\n",
    "\n",
    "        crossover_point = np.uint8(offspring_size[1] / 2)\n",
    "\n",
    "        for k in range(offspring_size[0]):\n",
    "            parent1_index = k % parents.shape[0]\n",
    "            parent2_index = (k + 1) % parents.shape[0]\n",
    "\n",
    "            # Generate a random number between 0 and 1\n",
    "            r = np.random.rand()\n",
    "\n",
    "            # If random number is less than crossover rate, perform crossover\n",
    "            if r < self.crossover_rate:\n",
    "                offspring[k, 0:crossover_point] = parents[parent1_index, 0:crossover_point]\n",
    "                offspring[k, crossover_point:] = parents[parent2_index, crossover_point:]\n",
    "            else:\n",
    "                offspring[k, :] = parents[parent1_index, :]\n",
    "\n",
    "        return offspring\n",
    "\n",
    "    \n",
    "    def mutation(self, offspring_crossover):\n",
    "        num_mutations = np.round(self.mutation_rate * self.genes)\n",
    "        mutation_indices = np.random.randint(0, offspring_crossover.shape[0], int(num_mutations))\n",
    "        for idx in mutation_indices:\n",
    "            random_value = np.random.uniform(-1.0, 1.0, 1)\n",
    "            gene_idx = np.random.randint(0, self.genes, 1)\n",
    "            offspring_crossover[idx, gene_idx] = random_value\n",
    "\n",
    "        return offspring_crossover\n",
    "\n",
    "    def run(self):\n",
    "        for i in range(self.generations):\n",
    "            fitness_population = self.fitness_function(self.X_train, self.population, self.y_train)\n",
    "            fitness_population=np.array(fitness_population)\n",
    "            \n",
    "            fitness_belief = self.fitness_function(self.X_train, self.belief_space, self.y_train)\n",
    "            \n",
    "\n",
    "            self.belief_space = self.acceptance_function(self.belief_space, self.population[0, :], fitness_belief, fitness_population[0])\n",
    "            \n",
    "            parents = self.influence_function(self.mating_parents, fitness_belief, fitness_population)\n",
    "\n",
    "            offspring_size = (self.chromosomes - parents.shape[0], self.genes)\n",
    "            \n",
    "            offspring_crossover = self.crossover(parents,offspring_size)\n",
    "            \n",
    "            offspring_mutation = self.mutation(offspring_crossover)\n",
    "            \n",
    "            #self.population[0, :] = self.belief_space[np.argmin(fitness_belief), :]\n",
    "            \n",
    "            #self.population[1:, :] = offspring_mutation[1:, :]\n",
    "            \n",
    "            self.population[0:parents.shape[0],:]=parents\n",
    "            \n",
    "            self.population[parents.shape[0]:,:]=offspring_mutation\n",
    "\n",
    "            #best_fitness = np.max(np.concatenate((fitness_belief, fitness_population)))\n",
    "            fitness=self.fitness_function(self.X_train,self.belief_space,self.y_train)\n",
    "            best_match_index=np.where(fitness==np.max(fitness))\n",
    "            best_fitness=fitness[best_match_index[0][0]]\n",
    "\n",
    "            print(\"Generation: {}/{} | Best fitness: {}\".format(i+1, self.generations, best_fitness))\n",
    "\n",
    "        self.best_weights=self.belief_space[np.where(fitness == np.max(fitness))][0]\n",
    "        \n",
    "    def predict(self,X_test):\n",
    "        prediction=self.forward(X_test,self.best_weights)\n",
    "        return prediction\n",
    "    \n",
    "    def reports(self,X_test,y_test):\n",
    "        prediction=self.forward(X_test,self.best_weights)\n",
    "        \n",
    "        print(f\"ACCURACY : {accuracy_score(y_test,prediction)}\\n\\n\\\n",
    "CLASSIFICATION REPORT :\\n {classification_report(y_test,prediction)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bf23d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "culturalnn=CulturalNN(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79aea76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: 1/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 2/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 3/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 4/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 5/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 6/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 7/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 8/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 9/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 10/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 11/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 12/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 13/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 14/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 15/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 16/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 17/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 18/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 19/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 20/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 21/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 22/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 23/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 24/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 25/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 26/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 27/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 28/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 29/30 | Best fitness: 0.7330729166666666\n",
      "Generation: 30/30 | Best fitness: 0.7330729166666666\n"
     ]
    }
   ],
   "source": [
    "culturalnn.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5717d6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY : 0.734375\n",
      "\n",
      "CLASSIFICATION REPORT :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.93      0.76        86\n",
      "           1       0.91      0.58      0.71       106\n",
      "\n",
      "    accuracy                           0.73       192\n",
      "   macro avg       0.78      0.75      0.73       192\n",
      "weighted avg       0.79      0.73      0.73       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "culturalnn.reports(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c0ed8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df3bc23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b85cba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b1203f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ec61a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c12ddcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9258fe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
